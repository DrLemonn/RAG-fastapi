import os
import numpy as np
from dotenv import load_dotenv
from langchain_text_splitters import MarkdownHeaderTextSplitter
from langchain_core.documents import Document
from langchain_openai import OpenAIEmbeddings

load_dotenv()

# --- 1. æ¨¡æ‹Ÿä½ çš„æ•°æ® ---
# è¯·æŠŠ docs/index.md é‡Œçš„çœŸå®å†…å®¹ï¼ˆå¤§çº¦å‰500å­—ï¼‰ç²˜è´´åˆ°è¿™é‡Œ
# åŠ¡å¿…ä¿è¯è¿™å’Œä½ æ–‡ä»¶é‡Œçš„å†…å®¹ä¸€æ¨¡ä¸€æ ·
raw_content = """# FastAPI

FastAPI æ˜¯ä¸€ä¸ªç”¨äºæ„å»º API çš„ç°ä»£ã€å¿«é€Ÿï¼ˆé«˜æ€§èƒ½ï¼‰çš„ web æ¡†æ¶ï¼Œä½¿ç”¨ Python å¹¶åŸºäºæ ‡å‡†çš„ Python ç±»å‹æç¤ºã€‚

å…³é”®ç‰¹æ€§:

* å¿«é€Ÿï¼šå¯ä¸ NodeJS å’Œ Go å¹¶è‚©çš„æé«˜æ€§èƒ½ï¼ˆå½’åŠŸäº Starlette å’Œ Pydanticï¼‰ã€‚æœ€å¿«çš„ Python web æ¡†æ¶ä¹‹ä¸€ã€‚
* é«˜æ•ˆç¼–ç ï¼šæé«˜åŠŸèƒ½å¼€å‘é€Ÿåº¦çº¦ 200ï¼… è‡³ 300ï¼…ã€‚
* æ›´å°‘ bugï¼šå‡å°‘çº¦ 40ï¼… çš„äººä¸ºï¼ˆå¼€å‘è€…ï¼‰å¯¼è‡´é”™è¯¯ã€‚
* æ™ºèƒ½ï¼šæä½³çš„ç¼–è¾‘å™¨æ”¯æŒã€‚å¤„å¤„çš†å¯è‡ªåŠ¨è¡¥å…¨ï¼Œå‡å°‘è°ƒè¯•æ—¶é—´ã€‚
* ç®€å•ï¼šè®¾è®¡çš„æ˜“äºä½¿ç”¨å’Œå­¦ä¹ ï¼Œé˜…è¯»æ–‡æ¡£çš„æ—¶é—´æ›´çŸ­ã€‚
* ç®€çŸ­ï¼šä½¿ä»£ç é‡å¤æœ€å°åŒ–ã€‚é€šè¿‡ä¸åŒçš„å‚æ•°å£°æ˜å®ç°ä¸°å¯ŒåŠŸèƒ½ã€‚bug æ›´å°‘ã€‚
* å¥å£®ï¼šç”Ÿäº§å¯ç”¨çº§åˆ«çš„ä»£ç ã€‚è¿˜æœ‰è‡ªåŠ¨ç”Ÿæˆçš„äº¤äº’å¼æ–‡æ¡£ã€‚
* æ ‡å‡†åŒ–ï¼šåŸºäºï¼ˆå¹¶å®Œå…¨å…¼å®¹ï¼‰API çš„ç›¸å…³å¼€æ”¾æ ‡å‡†ï¼šOpenAPI (ä»¥å‰è¢«ç§°ä¸º Swagger) å’Œ JSON Schemaã€‚
"""

# --- 2. æ¨¡æ‹Ÿä½ çš„åˆ‡åˆ†é€»è¾‘ ---
def test_split(text):
    # ä½ çš„é€»è¾‘æ˜¯æŒ‰ ## åˆ‡åˆ†
    headers_to_split_on = [("##", "section")]
    splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)
    # æ¨¡æ‹Ÿ Parent Document
    doc = Document(page_content=text, metadata={"source": "docs/index.md"})
    return splitter.split_text(doc.page_content)

# --- 3. è®¡ç®—ç›¸ä¼¼åº¦ (Cosine Similarity) ---
def cosine_similarity(vec_a, vec_b):
    norm_a = np.linalg.norm(vec_a)
    norm_b = np.linalg.norm(vec_b)
    if norm_a == 0 or norm_b == 0:
        return 0.0
    return np.dot(vec_a, vec_b) / (norm_a * norm_b)

def main():
    print(">>> æ­£åœ¨åˆå§‹åŒ– Embedding æ¨¡å‹...")
    embeddings = OpenAIEmbeddings(
        model="openai/text-embedding-3-small", 
        base_url="https://openrouter.ai/api/v1",
        api_key=os.getenv("OPENAI_API_KEY"),
    )

    raw_query = "FastAPI çš„æ ¸å¿ƒç‰¹æ€§æœ‰å“ªäº›ï¼Ÿ"
    print(f"\n>>> Query: {raw_query}")

    # 1. æ‰§è¡Œåˆ‡åˆ†
    chunks = test_split(raw_content)
    print(f">>> åˆ‡åˆ†ç»“æœ: ç”Ÿæˆäº† {len(chunks)} ä¸ª Chunk")


    
    # âŒ æ–¹å¼ 1: ç›´æ¥ embedding (ä½ ç°åœ¨çš„åšæ³•)
    print(f"\n>>> [æµ‹è¯• 1] åŸå§‹ Query: {raw_query}")
    query_vec_1 = embeddings.embed_query(raw_query)
    chunk_vec = embeddings.embed_query(chunks[0].page_content) # å‡è®¾åªæœ‰ä¸€ä¸ª chunk
    score_1 = cosine_similarity(query_vec_1, chunk_vec)
    print(f"ğŸ”¥ å¾—åˆ†: {score_1:.4f}")

    # âœ… æ–¹å¼ 2: åŠ ä¸ŠæŒ‡ä»¤å‰ç¼€ (Instruction)
    # ä¸åŒçš„æ¨¡å‹å‰ç¼€ä¸åŒï¼Œå¯¹äº Qwen/Alibaba ç³»åˆ—ï¼Œé€šå¸¸è¯•ç”¨ä»¥ä¸‹å‡ ç§ï¼š
    
    # å‰ç¼€ A (é€šç”¨æ£€ç´¢)
    prefix_a = "Represent this query for retrieving relevant documents: "
    query_a = prefix_a + raw_query
    
    # å‰ç¼€ B (ä¸­æ–‡è¯­å¢ƒ)
    prefix_b = "ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š"
    query_b = prefix_b + raw_query

    print(f"\n>>> [æµ‹è¯• 2] åŠ è‹±æ–‡å‰ç¼€ Query: {query_a}")
    query_vec_a = embeddings.embed_query(query_a)
    score_a = cosine_similarity(query_vec_a, chunk_vec)
    print(f"ğŸ”¥ å¾—åˆ†: {score_a:.4f}")

    print(f"\n>>> [æµ‹è¯• 3] åŠ ä¸­æ–‡å‰ç¼€ Query: {query_b}")
    query_vec_b = embeddings.embed_query(query_b)
    score_b = cosine_similarity(query_vec_b, chunk_vec)
    print(f"ğŸ”¥ å¾—åˆ†: {score_b:.4f}")

if __name__ == "__main__":
    main()