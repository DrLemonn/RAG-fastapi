import os
import pickle
import uuid
import shutil
from pathlib import Path
from typing import List
from dotenv import load_dotenv
from pprint import pprint

# å‡è®¾ cleaner æ˜¯ä½ ä¹‹å‰å®šä¹‰çš„æ¨¡å—
# import cleaner 

from langchain_text_splitters import MarkdownHeaderTextSplitter
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_pinecone import PineconeVectorStore
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import PromptTemplate
from langchain_core.documents import Document
from langchain_classic.storage import LocalFileStore, EncoderBackedStore # æ³¨æ„ï¼šlangchain_classic å¯èƒ½å·²å¼ƒç”¨ï¼Œå»ºè®®ç”¨ langchain.storage
from langchain_classic.retrievers import MultiVectorRetriever # åŒä¸Š

from pinecone import Pinecone, ServerlessSpec

# Load all environment variables
load_dotenv()

# --- é…ç½®é¡¹ ---
INDEX_NAME = "fastapi-cleaned"
LOCAL_STORE_PATH = "./parent_docs_store"

# åˆå§‹åŒ– Pinecone
pc = Pinecone(api_key=os.environ['PINECONE_API_KEY'])

def load_docs(path="./docs"):
    loader = DirectoryLoader(path, glob="**/*.md", loader_cls=TextLoader, loader_kwargs={"encoding": "utf-8"})
    return loader.load()

def split_markdown_by_h2(parent_doc: Document) -> List[Document]:
    headers_to_split_on = [("##", "section")]
    splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)
    child_docs = splitter.split_text(parent_doc.page_content)
    for child in child_docs:
        original_meta = child.metadata.copy()
        child.metadata.update(parent_doc.metadata) 
        child.metadata.update(original_meta)
    return child_docs

def get_retriever(docs=None, index_exists=False):
    embeddings = OpenAIEmbeddings(
        model="qwen/qwen3-embedding-8b", 
        base_url="https://openrouter.ai/api/v1",
        api_key=os.getenv("OPENAI_API_KEY"),
    )

    fs = LocalFileStore(LOCAL_STORE_PATH)
    store = EncoderBackedStore(
        store=fs,
        key_encoder=lambda x: x,
        value_serializer=pickle.dumps,
        value_deserializer=pickle.loads
    )

    if index_exists:
        print(f"æ£€æµ‹åˆ°ç´¢å¼• '{INDEX_NAME}' å·²å­˜åœ¨ï¼Œç›´æ¥åŠ è½½...")
        vectorstore = PineconeVectorStore.from_existing_index(index_name=INDEX_NAME, embedding=embeddings)
    else:
        print(f"ç´¢å¼• '{INDEX_NAME}' ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º...")
        pc.create_index(
            name=INDEX_NAME, 
            metric="cosine",
            spec=ServerlessSpec(cloud='aws', region='us-east-1'),
            dimension=4096 
        )
        vectorstore = PineconeVectorStore(index_name=INDEX_NAME, embedding=embeddings)

    retriever = MultiVectorRetriever(
        vectorstore=vectorstore,
        docstore=store,
        id_key="doc_id"
    )

    if not index_exists and docs:
        print("æ­£åœ¨å¤„ç†æ–‡æ¡£å¹¶ä¸Šä¼ ...")
        batch_parent_ids = []
        batch_parent_docs = []
        batch_child_docs = []

        for parent_doc in docs:
            parent_id = str(uuid.uuid4())
            child_docs = split_markdown_by_h2(parent_doc)
            for child in child_docs:
                child.metadata["doc_id"] = parent_id
            batch_parent_ids.append(parent_id)
            batch_parent_docs.append(parent_doc)
            batch_child_docs.extend(child_docs)

        retriever.docstore.mset(list(zip(batch_parent_ids, batch_parent_docs)))
        retriever.vectorstore.add_documents(batch_child_docs)
        print(f"æˆåŠŸå¤„ç†å¹¶å­˜å‚¨ {len(docs)} ä¸ªçˆ¶æ–‡æ¡£ã€‚")
    
    return retriever

def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)

# ==========================================
# ğŸ”¥ æ–°å¢åŠŸèƒ½ï¼šè°ƒè¯•å‘é‡æ£€ç´¢ç»“æœ
# ==========================================
def debug_retrieval(retriever, query, k=4):
    """
    ç»•è¿‡ MultiVectorRetriever çš„åˆå¹¶é€»è¾‘ï¼Œç›´æ¥æŸ¥çœ‹ VectorStore è¿”å›äº†ä»€ä¹ˆã€‚
    """
    print(f"\nğŸ” [Debug] æ­£åœ¨åˆ†æ Query: '{query}'")
    print("=" * 50)
    
    # ç›´æ¥è°ƒç”¨åº•å±‚çš„ vectorstore è¿›è¡Œå¸¦åˆ†æ•°çš„æœç´¢
    # æ³¨æ„ï¼šPinecone çš„ score å¦‚æœæ˜¯ cosineï¼Œé€šå¸¸æ˜¯ 0-1 ä¹‹é—´ï¼ˆè¶Šæ¥è¿‘ 1 è¶Šç›¸ä¼¼ï¼‰
    results = retriever.vectorstore.similarity_search_with_score(query, k=k)
    
    seen_parent_ids = set()
    
    for i, (doc, score) in enumerate(results):
        doc_id = doc.metadata.get("doc_id", "Unknown")
        is_duplicate_parent = doc_id in seen_parent_ids
        seen_parent_ids.add(doc_id)
        
        status = "âœ… (å°†è¢«é‡‡ç”¨)" if not is_duplicate_parent else "ğŸ”» (å°†è¢«å»é‡)"
        
        print(f"Chunk #{i+1} | Score: {score:.4f} | Parent ID: {doc_id}")
        print(f"çŠ¶æ€: {status}")
        # å…ˆåœ¨å¤–éƒ¨å¤„ç†å¥½å­—ç¬¦ä¸²
        preview_text = doc.page_content[:100].replace('\n', ' ')
        print(f"å†…å®¹ç‰‡æ®µ: {preview_text}...")
        print("-" * 50)
        
    print(f"ğŸ“Š æœ€ç»ˆå»é‡åï¼ŒRAG å°†è·å¾— {len(seen_parent_ids)} ä¸ªå®Œæ•´çš„çˆ¶æ–‡æ¡£ä½œä¸ºä¸Šä¸‹æ–‡ã€‚")
    print("=" * 50 + "\n")

def main():
    # 1. åˆå§‹åŒ–ç¯å¢ƒ
    index_exists = pc.has_index(INDEX_NAME)
    docs = None
    if not index_exists:
        print(">>> åˆå§‹åŒ–æ¨¡å¼ <<<")
        docs = load_docs("./docs")
        # for doc in docs: doc.page_content = cleaner.clean_fastapi_markdown(doc.page_content) 
    
    # 2. è·å– Retriever
    retriever = get_retriever(docs=docs, index_exists=index_exists)

    # 3. å®šä¹‰ Query
    query = "FastAPI çš„æ ¸å¿ƒç‰¹æ€§æœ‰å“ªäº›ï¼Ÿ"
    print(f"æé—®: {query}")

    # 4. ğŸ”¥ æ‰§è¡Œè°ƒè¯•ï¼šæŸ¥çœ‹å–å‡ºäº†å“ªäº› Chunk ä»¥åŠåˆ†æ•°
    debug_retrieval(retriever, query, k=5)

    # # 5. æ‰§è¡Œæ­£å¸¸çš„ RAG æµç¨‹
    # print(">>> å¼€å§‹æ‰§è¡Œ RAG ç”Ÿæˆ...")
    # prompt_temp = """ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹ã€‚è¯·æ ¹æ®ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚
    # é—®é¢˜ï¼š {question} 
    # ä¸Šä¸‹æ–‡ï¼š {context} 
    # ç­”æ¡ˆï¼š"""
    # prompt = PromptTemplate.from_template(prompt_temp)
    # llm = ChatOpenAI(
    #     model="deepseek/deepseek-r1-0528:free", 
    #     openai_api_key=os.getenv("OPENAI_API_KEY"),
    #     base_url="https://openrouter.ai/api/v1", 
    #     temperature=0.6 
    # )

    # rag_chain = (
    #     {"context": retriever | format_docs, "question": RunnablePassthrough()}
    #     | prompt
    #     | llm
    #     | StrOutputParser()
    # )
    
    # result = rag_chain.invoke(query)
    # print("\nğŸ¤– AI å›ç­”:")
    # pprint(result)

if __name__ == "__main__":
    main()